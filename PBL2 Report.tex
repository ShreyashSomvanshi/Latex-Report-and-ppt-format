\documentclass[pdftex,a4paper,11pt,oneside,openright]{report}
\usepackage{listings} %start of code insertion syntax
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
} %end of code insertion syntax
\usepackage[dvips]{graphics}
\usepackage{color}
\usepackage{algorithm,algorithmic}
\usepackage{epsfig}
\usepackage{pseudocode,fancybox, fancyhdr}
\usepackage{pgothic}
\usepackage[T1]{fontenc}
\usepackage{yfonts}
\usepackage[T1]{fontenc}
%\usepackagen{fonts}
\usepackage[T1]{fontenc}
\usepackage{duerer}
\usepackage[T1]{fontenc}
\usepackage{trajan}
\usepackage[T1]{fontenc}
\usepackage{fancyvrb}
\usepackage{fancyhdr}
\usepackage{anysize}
\usepackage{coeptitle}   %% Thesis Title Page
\usepackage{latexsym}
%\usepackage{pictex}
\usepackage{fancyvrb}
\usepackage{fancyhdr}
\usepackage{color}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{rawfonts}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{yfonts}
%\usepackage{arev}
\usepackage{algorithm}
\usepackage[T1]{fontenc}
\pagestyle{headings}
%\pagestyle{fancy}
\usepackage{yfonts}
\usepackage[pdftex,
        colorlinks=true,
        urlcolor=black,       % \href{...}{...} external (URL)
        filecolor=black,     % \href{...} local file
        linkcolor=black,       % \ref{...} and \pageref{...}
	citecolor=black,
        pdftitle={BE Project Report},
        pdfauthor={Your name},
        pdfsubject={Project Title},
        pdfkeywords={ACM Key words},
%        pagebackref,
%        pdfpagemode=true,
         bookmarksopen=true]{hyperref}
\setlength{\textwidth}{6.27in}
\setlength{\textheight}{9.69in}
\setlength{\topmargin}{0.0in}
\setlength{\oddsidemargin}{0.0in}			% Customisable
\setlength{\headheight}{0.1in}
\setlength{\headsep}{0.2in}
\setlength{\topskip}{0.0in}
\fontencoding{T1}		% Font specification : Times New Roman, Bold, Normal, 18
\fontfamily{cmr}		% Roman
\fontseries{m}			% Medium
\fontshape{n}			% Upright
\fontsize{10pt}{3}		
\linespread{1.5}		% Vertical spacing between lines
\selectfont			% Select the specified font
\usepackage{tikz}
%\chapterstyle{lyhne}
\usepackage{tikz, lipsum}% http://ctan.org/pkg/{pgf,lipsum}
\newcommand*{\chapnumfont}{\normalfont\sffamily\huge\bfseries}
\newcommand*{\printchapternum}{
  \begin{tikzpicture}
    \draw[fill,color=black] (0,0) rectangle (2cm,2cm);
    \draw[color=white] (1cm,1cm) node { \chapnumfont\thechapter };
  \end{tikzpicture}
}
\newcommand*{\chaptitlefont}{\normalfont\sffamily\Huge\bfseries}
\newcommand*{\printchaptertitle}[1]{\flushright\chaptitlefont#1}

\makeatletter
% \@makechapterhead prints regular chapter heading.
% Taken directly from report.cls and modified.
\def\@makechapterhead#1{%
  \vspace*{50\p@}%
  {\parindent \z@ \raggedleft
    \ifnum \c@secnumdepth >\m@ne
        \printchapternum
        \par\nobreak
        \vskip 20\p@
    \fi
    \interlinepenalty\@M
    \printchaptertitle{#1}\par\nobreak
    \vskip 40\p@
  }}
% \@makeschapterhead prints starred chapter heading.
% Taken directly from report.cls and modified.
\def\@makeschapterhead#1{%
  \vspace*{50\p@}%
  {\parindent \z@ \raggedleft
    \interlinepenalty\@M
    \printchaptertitle{#1}\par\nobreak
    \vskip 40\p@
  }}
\makeatother
\begin{document}	% Start of Report

\pagestyle{fancy}
\DeclareGraphicsExtensions{.png, .ps}
\begin{titlepage}
\begin{center}
\LARGE{\bf{\textsc{DIABETES PREDICTION USING MACHINE LEARNING}\\}}	% LARGE = 17.28
\vspace{10pt}
\textsc{{\small A\\  \small  Project Based Learning Report\\}}		% Large = 14.40
\textsc{{\small Submitted \\ \small by\\}}
\begin{table}[htbp]
	\begin{center}
	\begin{tabular}{ l c c l }
	\large\bf{Mr. Shreyash Somvanshi} & & &  \large\bf{2127062} \\[0.3cm] 
        \large\bf{Mr. Sujay Shinde}& & &  \large\bf{2127063} \\[0.3cm]
	\large\bf{Mr. Prajwal Rudrapwar}& & & \large\bf{2127076}   \\[0.3cm]
	\large\bf{Ms. Vedanti Mane}& & & \large\bf{2127073}
	\\[0.3cm]
	\large\bf{Ms. Trupti Kharat}& & & \large\bf{2127032}
		\end{tabular}
	\end{center}
	\end{table}
\textsc{{ \small In partial fulfillment for the requirement of Project Based Learning-II\\ \vspace{1.5pt}of\\}}
\LARGE{{\swabfamily Bachelor of Artificial Intelligence and Data Science\\}}% Mention only appropriate degree.
\vspace{20pt}
%names of advisors
\large{Under the guidance of\\ }
\Large{\bf{Prof. Rajkumar Panchal}\\}
\large{(Assistant Professor)}\\
%\Large{Vidya Pratishthan's College of Engineering, Baramati\\}
\vspace{10pt}
\begin{figure}[!h]
\begin{center}
%\includegraphics{figures/multihop_network}
\includegraphics[height=40mm, width=35mm]{vpkbiet.png}
%\caption{2: Clustering Model}\label{fig:clu}
\end{center}
\end{figure}
\vspace{-.6cm}
\LARGE{\bf{\textsc{Department of Artificial Intelligence and Data Science}}}\\
\Large{ \textsc{Vidya Pratishthan's Kamalnayan Bajaj Institute of Engineering and Technology}}\\
\large{Bhigwan Road, Vidyanagari}\\
\large{Baramati-413133}\\
%\vfill
\large{2021-2022}
\end{center}
\end{titlepage}
\thispagestyle{empty}
\vspace{-50pt}
\begin{figure}[!h]
\begin{center}
%\includegraphics{figures/multihop_network}
\includegraphics[height=40mm, width=35mm]{vpkbiet.png}
%\caption{2: Clustering Model}\label{fig:clu}
\vspace{-.8cm}
\end{center}
\end{figure}
\begin{center}			% LARGE = 18
\linespread{1}
	\small{Vidya Pratishthan's} \\ \large{Kamalnayan Bajaj Institute of Engineering and Technology, Baramati}\\	
	\Large{\bf{Department of Artificial Intelligence and Data Science}}\\
	
\end{center}

%\vspace{pt}			% Vertical space between dept name and ``certi''
\begin{center}
\Huge{{\swabfamily Certificate\\}}
	
\end{center}

\vspace{12pt}

\linespread{1}			% Double spacing between lines
\selectfont
\large{
\textsc{This is to certify that following students} 
\begin{table}[htbp]
	\begin{center}
	\begin{tabular}{ l c c l }
	
	\large\bf{Mr. Shreyash Somvanshi} & & & \large\bf{2127062} \\ [0.3cm]
\large\bf{Mr. Sujay Shinde} & & & \large\bf{2127063} \\ [0.3cm]
\large\bf{Mr. Prajwal Rudrapwar} & & & \large\bf{2127076} \\ [0.3cm]
\large\bf{Ms. Vedanti Mane} & & & \large\bf{2127073} \\ [0.3cm]
\large\bf{Ms. Trupti Kharat} & & & \large\bf{2127032} \\ [0.3cm]
		\end{tabular}
	\end{center}
	\end{table} \\
		\textsc{	have successfully completed their project work on}
	\begin{center}
	  {\bf DIABETES PREDICTION USING MACHINE LEARNING}
	\end{center}
\textsc{during the academic year \textbf{2021-2022} in the partial fulfillment towards the completion of \textbf{Project Based Learning-II} in \textbf{Artificial Intelligence and Data Science}}
}

\vspace{60pt}

\begin{center}		% Horizontal spacing used to keep the signatures in columns at the ends of
% lines

Project Guide\hspace{\stretch{1}}Head, Deptt.of AI $\&$ DS\\
\normalsize{\bf{{(Rajkumar Panchal) }\hspace{\stretch{1}}(Digambar Padulkar)}\\
%\small{Assistant Professor\hspace{\stretch{1}}Assistant Professor}\\
}
\vspace{60pt}
Principal\\
(\bf Dr. R. S. Bichkar) \\
%\small{Assistant Professor\hspace{\stretch{1}}Assistant Professor}\\


\vspace{60pt}
\bf{Internal Examiner\hspace{\stretch{1}}External Examiner}\\
\end{center}
\newpage
\pagenumbering{roman}

\chapter*{\begin{center}\Huge{Acknowledgments}\end{center}}
%\thispagestyle{empty}
\addcontentsline{toc}{chapter}{{Acknowledgments}}
\Large{We express our deep sense of gratitude to all those who have been instrumental in preparation of this project.We are thankful to all the faculties of Deptt.of AI and DS for their constant support, guidance and encouragement.
We acknowledge the kind of support, efforts and timely guidance provided by Prof.Rajkumar Panchal sir.This project report helps in better understanding of the subject matter.
We also like to express regards to the books and internet and linkedin conections who provided us with subject related insights.}
\begin{flushright}
\textbf{Mr. Shreyash Somvanshi}\\ 
\textbf{Mr. Sujay Shinde      }\\
\textbf{Mr. Prajwal Rudrapwar } \\
\textbf{Ms. Vedanti Mane      } \\
\textbf{Ms. Trupti Kharat     } \\
\end{flushright}


\chapter*{\begin{center}\Huge{ABSTRACT}\end{center}}
\Large{Diabetes is a chronic disease with the potential to cause a worldwide health care crisis. According to International Diabetes Federation 382 million people are living with diabetes across the whole world. By 2035, this will be doubled as 592 million. Diabetes is a disease caused due to the increase level of blood glucose. This high blood glucose produces the symptoms of frequent urination, increased thirst, and increased hunger. Diabetes is a one of the leading cause of blindness, kidney failure, amputations, heart failure and stroke. When we eat, our body turns food into sugars, or glucose. At that point, our pancreas is supposed to release insulin. Insulin serves as a key to open our cells, to allow the glucose to enter and allow us to use the glucose for energy. But with diabetes, this system does not work. Type 1 and type 2 diabetes are the most common forms of the disease, but there are also other kinds, such as gestational diabetes, which occurs during pregnancy, as well as other forms. Machine learning is an emerging scientific field in data science dealing with the ways in which machines learn from experience. The aim of this project is to develop a system which can perform early prediction of diabetes for a patient with a higher accuracy by combining the results of different machine learning techniques. The algorithms like K nearest neighbour, Logistic Regression, Random forest, Support vector machine and Decision tree are used. The accuracy of the model using each of the algorithms is calculated. Then the one with a good accuracy is taken as the model for predicting the diabetes.} 

\onehalfspacing
%\chapter*{\begin{center} {\Huge{Abstract}}\end{center}}
\addcontentsline{toc}{chapter}{{Abstract}}
%\subparagraph{}
%\renewcommand{\footrulewidth } {1.5pt}
%\renewcommand{\headrulewidth}{1.2pt}
\lfoot{\small \it Diabetes Prediction Using Machine Learning}
\rfoot{\small \it VPKBIET, Baramati}
\lhead{}


\tableofcontents	
\addtocontents{toc}{\protect\thispagestyle{empty}} 
%\listoftables
%\addcontentsline{toc}{chapter}{}
%\listoffigures
%\addcontentsline{toc}{chapter}{List of Figures}
%\chapter*{List of Symbols}
%\addcontentsline{toc}{chapter}{List of Symbols}

\newpage
		% Change to Arabic numbers for main chapters.
\pagenumbering{arabic}


\chapter{\bf Synopsis }
\section{\bf Title}
\large{\bf DIABETES PREDICTION USING MACHINE LEARNING}
%\section{Brief Description}
%\section{Problem Definition}
%\section{Applying Software Engineering Approach}

\section{Technical Keywords}
\Large{Machine Learning, Diabetes, Decision tree, Train-Test-Split, K nearest neighbour, Logistic Regression, Support vector Machine, Accuracy.} 

\chapter{Problem Statement}
\Large{Make use of new emerging technologies in the healthcare to reduce time and efforts.}
\section{Goals and Objectives}
\Large{To use modern technologies to increase accuracy and automation in healthcare}
\section{Statement of Scope}
\Large{This Diabetes Prediction using Machine Learning works for Healthcare domain.It has 80\% accuracy in predicting diabetes based on the factors like patient's insulin, glucose level, age,etc. factors. This Diabetes Prediction Model makes use of various classification Algorithms to categorize patients into diabetic and non-diabetic.}

%\chapter{ABSTRACT}
%\Large{} 

\chapter{Area Project}
\Large{This Diabetes Prediction using Machine Learning works for Healthcare domain.It has 80\% accuracy in predicting diabetes based on the factors like patient's insulin, glucose level, age,etc. factors.  }

\chapter{Methodology of Problem Solving}
\begin{enumerate}
    \item Import the dataset with various patient records on parameters like age, insulin, glucose, blood pressure.
    \item Clean the dataset i.e. remove the unwanted constraints (Preprocessing)
    \item Perform train-test-split on processed dataset
    \item Use the preffered algorithm
    \item Compare and check accuracy
\end{enumerate}
\chapter{Introduction}
\section{Motivation of the Project}
\Large{Motive of this project is to use the Artificial Intelligence technologies like Machine Learning in healthcare sector to increase efficiency and accuracy of results }
\section{Literature Survey}
\Large{This Diabetes Prediction Model makes use of various classification Algorithms to categorize patients into diabetic and non-diabetic.}\\
\Large{Currently we have achieved 80\% accuracy but it can be made more precise with help of appropriate data processing.}

\chapter{Dataset Description}
\begin{enumerate}
    \item This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database.
    \item Dataset used for this model is located on "https://raw.githubusercontent.com/ShreyashSomvanshi/Datasets/main/Diabetes.csv" 
    \item It consists the detailed records of patients.The attributes in datasets are Age, Insulin, Pregnancies, Glucose, DiabetesPedigreeFunction, BMI, Blood pressure,etc
    \item Dataset consists of 768 rows and 9 columns
    
    
\end{enumerate}

\chapter{Libraries and Functions used}
%{We have used following Packages/Libraries:}
\Large{Libraries: }
\Large{
\begin{enumerate}
    \item pandas
    \item numpy
    \item sklearn
\end{enumerate}
\Large{Functions/Modules used from sklearn: }
\begin{enumerate}
    \item sklearn.model\_selection import train\_test\_split
    \item sklearn.metrics import mean\_absolute\_error
    \item sklearn.linear\_model import LogisticRegression
    \item sklearn.linear\_model import LinearRegression
    \item sklearn.metrics import accuracy\_score
    \item sklearn.neighbors import KNeighborsClassifier
    \item sklearn.naive\_bayes import GaussianNB
    \item sklearn.svm import SVC
    \item sklearn.tree import DecisionTreeClassifier
\end{enumerate}
}

\chapter{Project Planning}
\centering
\includegraphics[height=90mm, width=150mm]{Screenshot 2022-05-11 225556.png}

\chapter{Class Diagram}
\centering
\includegraphics[height=110mm, width=160mm]{Class Diagram.png}

\chapter{Architecture}
\includegraphics[height=90mm, width=150mm]{ucdlatex.png}
%\chapter{Result Analysis}
    %\section{Graphs}
    %\includegraphics[height=60mm, width=80mm]{1.png}
    %\includegraphics[height=60mm, width=80mm]{2.png}
    %\includegraphics[height=60mm, width=80mm]{3.png}
    %\includegraphics[height=60mm, width=80mm]{4.png}
    %\includegraphics[height=60mm, width=80mm]{5.png}

    %\section{section title goes here}
    %\section{section title goes here}
%\subsection{sub section title goes here}
\chapter{Code}
\begin{lstlisting}
# -*- coding: utf-8 -*-
"""PBL2DiabetesPredictionUsingML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IpgIYr-Vhc95CbLqkOEK78A8P8njEYoE
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
import warnings
warnings.filterwarnings('ignore')

"""https://raw.githubusercontent.com/ShreyashSomvanshi/Datasets/main/Diabetes.csv

"""

dataset = pd.read_csv(r'https://raw.githubusercontent.com/ShreyashSomvanshi/Datasets/main/Diabetes.csv')

"""https://github.com/Yantra-Byte/Dataset/raw/main/Diabetes.csv"""

dataset.head()

dataset.tail()

dataset.shape

dataset.info()

dataset.isnull().sum()

dataset.describe()

"""Visualizing Data"""

# Now we will be imputing the mean value of the column to each missing value of that particular column
dataset['Glucose'].fillna(dataset['Glucose'].mean(), inplace = True)
dataset['BloodPressure'].fillna(dataset['BloodPressure'].mean(), inplace = True)
dataset['SkinThickness'].fillna(dataset['SkinThickness'].median(), inplace = True)
dataset['Insulin'].fillna(dataset['Insulin'].median(), inplace = True)
dataset['BMI'].fillna(dataset['BMI'].median(), inplace = True)

# Now, let's check that how well our outcome column is balanced
color_wheel = {1: "#0392cf", 2: "#7bc043"}
colors = dataset["Outcome"].map(lambda x: color_wheel.get(x + 1))
print(dataset.Outcome.value_counts())
p=dataset.Outcome.value_counts().plot(kind="pie")

dataset['Outcome'].value_counts()

# Plotting the distributions after removing the NAN values
p = dataset.hist(figsize = (20,20))

"""Correlation Matrix

"""

# Correlation between all the features before cleaning
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12,10))
p = sns.heatmap(dataset.corr(), annot=True,cmap ='Reds')  # seaborn has an easy method to showcase heatmap

X = dataset.drop(columns='Outcome',axis=1)

y = dataset['Outcome']

X
y

"""#Declaring Training and Testing Data"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 0)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

#from sklearn.linear_model import LogisticRegression
#from sklearn.neighbors import KNeighborsClassifier
#from sklearn.naive_bayes import GaussianNB
#from sklearn.svm import SVC
#from sklearn.tree import DecisionTreeClassifier
#from sklearn.ensemble import RandomForestClassifier

#model = LogisticRegression()
#model = KNeighborsClassifier()
#model = GaussianNB()
#model = SVC()
#model = DecisionTreeClassifier()
#model = RandomForestClassifier()

"""#Logistic Regression"""

modl = LogisticRegression()
modelLR = modl.fit(X_train, y_train)
X_train_pred = modelLR.predict(X_train)
trainingData_accuracy = accuracy_score(X_train_pred, y_train)
print("Accuracy on Training Data : ", trainingData_accuracy)
X_test_pred = modelLR.predict(X_test)
testData_accuracy = accuracy_score(X_test_pred, y_test)
print("Accuracy on Test Data : ", testData_accuracy)

# from sklearn.metrics import classification_report, confusion_matrix

# print(confusion_matrix(y_test, X_test_pred))
# print(classification_report(y_test, X_test_pred))

"""#K Neighbors Classifier"""

modl = KNeighborsClassifier()
modelKNN = modl.fit(X_train, y_train)
X_train_pred = modelKNN.predict(X_train)
trainingData_accuracy = accuracy_score(X_train_pred, y_train)
print("Accuracy on Training Data : ", trainingData_accuracy)
X_test_pred = modelKNN.predict(X_test)
testData_accuracy = accuracy_score(X_test_pred, y_test)
print("Accuracy on Test Data : ", testData_accuracy)

"""#Support Vector Machine"""

model = SVC()
modelSVM = modl.fit(X_train, y_train)
X_train_pred = modelSVM.predict(X_train)
trainingData_accuracy = accuracy_score(X_train_pred, y_train)
print("Accuracy on Training Data : ", trainingData_accuracy)
X_test_pred = modelSVM.predict(X_test)
testData_accuracy = accuracy_score(X_test_pred, y_test)
print("Accuracy on Test Data : ", testData_accuracy)

"""#Decision Tree"""

modl = DecisionTreeClassifier()
modelDT = modl.fit(X_train, y_train)
X_train_pred = modelDT.predict(X_train)
trainingData_accuracy = accuracy_score(X_train_pred, y_train)
print("Accuracy on Training Data : ", trainingData_accuracy)
X_test_pred = modelDT.predict(X_test)
testData_accuracy = accuracy_score(X_test_pred, y_test)
print("Accuracy on Test Data : ", testData_accuracy)

"""#Naive Bayes"""

modl = GaussianNB()
modelNB = modl.fit(X_train, y_train)
X_train_pred = modelNB.predict(X_train)
trainingData_accuracy = accuracy_score(X_train_pred, y_train)
print("Accuracy on Training Data : ", trainingData_accuracy)
X_test_pred = modelNB.predict(X_test)
testData_accuracy = accuracy_score(X_test_pred, y_test)
print("Accuracy on Test Data : ", testData_accuracy)

"""#Conclusion from Training and Testing Accuracies of different algorithms used:

% <table>
%   <tr>
%     <th> Algorithm </th>
%     <th> Testing Accuracy </th>
%     <th> Training Accuracy </th>
%   </tr>
%   <tr>
%     <td>Logistic Regression</td>
%     <td>0.7792</td>
%     <td>0.7636</td>
%   </tr>
%   <tr>
%     <td>Naive Bayes</td>
%     <td>0.7619</td>
%     <td>0.7673</td>
%   </tr>
%   <tr>
%     <td>Decision Tree</td>
%     <td>0.7533</td>
%     <td>1.0</td>
%   </tr>
%   <tr>
%     <td>SVM</td>
%     <td>0.7489</td>
%     <td>0.7896</td>
%   </tr>
%   <tr>
%     <td>KNN Classifier</td>
%     <td>0.7489</td>
%     <td>0.7896</td>
%   </tr>
% </table>

1.In Logistic Regression this accuracy is not valid as its testing accuracy is less than training accuracy.Training accuracy must always be greater than Testing Accuracy.

2.Naive Bayes accuracy we got is valid, and we may use it.

3.Decision Tree gave us the Training accuracy of 100% but this is not valid because we are using a part of training data for testing. At the time of training, decision tree gained knowledge about that data, and now if you give same data to predict it will give exactly same value. That's why decision tree producing correct results every time.

4.Support Vector Machine has given descent accuracy but not as much as Naive Bayes.

5.KNN classifier has also given same accuracy as of SVM.

#Building a Prediction System

So from above conclusions we may either use SVM or KNN. Here we will be using SVM
"""
# (pd.Series(modl.feature_importances_, index=X.columns)
#    .plot(kind='barh'))

dataset.tail()

inputData=(5,121,72,23,112,26.2,0.245,30)
#inputData=(1,126,60,0,0,30.1,0.349,47) for this data at 766 LR,NB,gave wrong outputs.

"""Convert input data to numpy array"""

inputDataNumpyArray = np.asarray(inputData)

"""Reshape the numpyy array as we are predicting for only one instance"""

inputDataReshaped = inputDataNumpyArray.reshape(1,-1)

prediction = modelSVM.predict(inputDataReshaped)
print(prediction)

if (prediction[0]==0):
  print("The patient doesn't have Diabetes. ")
else:
  print("The patient is Diabetic. ")

\end{lstlisting}


\chapter{Result Analysis}
\centering
\includegraphics[height=100mm, width=150mm]{graphss.png}
 \section{Correlation Matrix}
    \centering
    \includegraphics[height=110mm, width=150mm]{correln.png}
 \section{Dependent Attribute}
    \centering
    \includegraphics[height=90mm, width=160mm]{dependent on.png}

\chapter{Application}
\Large{As the technology in each domain is progressing rapidly, this Machine Learning based Diabetes Prediction Model can also come in normal usage.This can also be updated with the future technological trends.It can adapt the changes without much complications.Now-a-days the covid self testing kits are available in the market similarly this can also be used for testing the Diabetic diseases without going to the hospitals. } 

\chapter{Constraints}
\Large{*Medical tests are required to get the accurate values of insulin , glucose , blood pressure of patients.}\\
\Large{*Results may change as we are testing on human body not a machine.}

\chapter{Software/Hardware Resources}
\Large{*Software Resources:}
\begin{enumerate}
    \item Python 3.9
    \item Jupyter notebook
    \item Github
\end{enumerate}
\Large{*Hardware Resources:}
\begin{enumerate}
    \item 4GB RAM
    \item 1GB Storage space
    \item Intel core i3 processor
\end{enumerate}

\chapter{Conclusion}
\Large{One of the important real-world medical problems is the detection of diabetes at its early stage. In this study, systematic efforts are made in designing a system which results in the prediction of diabetes. During this work, five machine learning classification algorithms are studied and evaluated on various measures. Experiments are performed on john Diabetes Database. Experimental results determine the adequacy of the designed system with an achieved accuracy of 80\% Using Decision Tree Algorithm. In future, the designed system with the used machine learning classification algorithms can be used to predict or diagnose other diseases. The work can be extended and improved for the automation of diabetes analysis including some other machine learning algorithms. }

%\appendix
%\chapter{Glossary}
%Defines Terms, Acronyms and abbreviations used in the FRD
%\chapter*{Annex  A}
%Define terms, acronyms, and abbreviations used in the FRD
\end{document}			% End of Report
